{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "import random\n",
    "\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "ALPHABET = string.ascii_lowercase\n",
    "N_LETTERS = len(ALPHABET)\n",
    "N_LETTERS\n",
    "\n",
    "CHARS = string.ascii_lowercase + u' '\n",
    "\n",
    "PUNCTUATION_REMOVER = {\n",
    "    ord(c): None \n",
    "    for c in string.punctuation + string.digits\n",
    "}\n",
    "PUNCTUATION_REMOVER.update({\n",
    "    ord(u'\\xe6'): None,\n",
    "    ord(u'\\xe8'): None,\n",
    "    ord(u'\\xe9'): None,\n",
    "    ord(u'\\xee'): None,\n",
    "    ord(u'\\x1a'): None\n",
    "})\n",
    "\n",
    "LETTER_TO_INDEX = {str(s): i for i, s in enumerate(string.ascii_lowercase + u' ')}\n",
    "\n",
    "def wordify(i):\n",
    "    return CHARS[i]\n",
    "def numbrify(msg):\n",
    "    return [LETTER_TO_INDEX[m] for m in msg]\n",
    "\n",
    "wordify = np.vectorize(wordify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vammgwbgumr\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "def clean(s):\n",
    "    return \" \".join(s.translate(PUNCTUATION_REMOVER).lower().split())\n",
    "\n",
    "class Cipher(object):\n",
    "    chars = str(string.ascii_lowercase + ' ')\n",
    "    ords = tuple(ord(c) for c in chars)\n",
    "    n_chars = len(chars)\n",
    "    \n",
    "    def __init__(self, encoder):\n",
    "        self._encoder = {ord(k): ord(v) for k, v in encoder.items()}\n",
    "        self._decoder = {ord(v): ord(k) for k, v in encoder.items()}\n",
    "        \n",
    "    @classmethod\n",
    "    def get_random_cipher(cls):\n",
    "        c = Cipher({c: c for c in cls.chars})\n",
    "        return c.mutate_key(27)\n",
    "    \n",
    "    @property\n",
    "    def encoder(self):\n",
    "        return deepcopy(self._encoder)\n",
    "    \n",
    "    @property\n",
    "    def encoder_matrix(self):\n",
    "        m = np.zeros((self.n_chars, self.n_chars))\n",
    "    \n",
    "    @property\n",
    "    def decoder(self):\n",
    "        return deepcopy(self._decoder)\n",
    "    \n",
    "    def encipher(self, msg):\n",
    "        msg = clean(str(msg))\n",
    "        return msg.translate(self._encoder)\n",
    "    \n",
    "    def decipher(self, msg):\n",
    "        return msg.translate(self._decoder)\n",
    "    \n",
    "    def mutate_key(self, n_swaps):\n",
    "        to_swap = random.sample(self.ords, n_swaps)\n",
    "        candidates = [self.encoder[c] for c in to_swap]\n",
    "        random.shuffle(candidates)\n",
    "        self._encoder.update(dict(zip(to_swap, candidates)))\n",
    "        self._decoder = {v: k for k, v in self._encoder.items()}\n",
    "        return self\n",
    "        \n",
    "c = Cipher.get_random_cipher()\n",
    "print(c.encipher('hello world'))\n",
    "print(c.decipher(c.encipher('hello world')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = \" \".join(str(clean(nltk.corpus.gutenberg.raw())).lower().split())\n",
    "# with open('gutenberg.txt', 'w') as f:\n",
    "#     f.write(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({' ': 2102545,\n",
       "         'a': 731203,\n",
       "         'b': 139846,\n",
       "         'c': 185849,\n",
       "         'd': 400494,\n",
       "         'e': 1119617,\n",
       "         'f': 209239,\n",
       "         'g': 172048,\n",
       "         'h': 650743,\n",
       "         'i': 577691,\n",
       "         'j': 15946,\n",
       "         'k': 66676,\n",
       "         'l': 375313,\n",
       "         'm': 230032,\n",
       "         'n': 615091,\n",
       "         'o': 678136,\n",
       "         'p': 136173,\n",
       "         'q': 7552,\n",
       "         'r': 502402,\n",
       "         's': 556863,\n",
       "         't': 827161,\n",
       "         'u': 252211,\n",
       "         'v': 83829,\n",
       "         'w': 201292,\n",
       "         'x': 9160,\n",
       "         'y': 176040,\n",
       "         'z': 5525})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_counts = Counter(corpus)\n",
    "letters = sorted(letter_counts.keys())\n",
    "n_letters = len(letters)\n",
    "letter_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_letter_probs = np.array([letter_counts[l] for l in letters])\n",
    "init_letter_probs = np.log(init_letter_probs / init_letter_probs.sum())\n",
    "\n",
    "def get_trans(n_elements, element_to_index, corpus, order=1, smoothing_factor=1):\n",
    "    \"\"\"\n",
    "    Returns a matrix of log transition probabilities, T, where T[ix] is the \n",
    "    conditional probability of seeing element ix[-1] after sequence ix[:-1]\n",
    "    \"\"\"\n",
    "    trans = np.ones((n_elements,)*(1 + order)) * smoothing_factor \n",
    "    \n",
    "    for i in range(len(corpus) - order):\n",
    "        ix = tuple(element_to_index[e] for e in corpus[i: i + order + 1])\n",
    "        trans[ix] += 1\n",
    "\n",
    "    return np.log(trans / trans.sum(axis=1, keepdims=True))\n",
    "\n",
    "letter_trans_probs = get_trans(n_letters, LETTER_TO_INDEX, corpus, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_likelihood(message, init_probs, trans_probs, element_to_index):\n",
    "    \"\"\"\n",
    "    Returns the likelihood of a given message according\n",
    "    to probabilities init_probs and trans_probs, where element_to_index\n",
    "    converts from characters (or words if message is a list of words) to \n",
    "    array indicies.\n",
    "    \"\"\"\n",
    "    order = trans_probs.ndim - 1\n",
    "    prob = 0\n",
    "    for i in range(len(message)):\n",
    "        if i < order:\n",
    "            prob += init_probs[element_to_index[message[i]]] \n",
    "        else: \n",
    "            ix = tuple(element_to_index[e] for e in message[i - order: i + 1])\n",
    "            prob += trans_probs[ix]\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.7576406633606396"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_likelihood = lambda x: get_likelihood(x, init_letter_probs, letter_trans_probs, LETTER_TO_INDEX)\n",
    "get_likelihood('car', init_letter_probs, letter_trans_probs, LETTER_TO_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mapping():\n",
    "    m = np.identity(27)\n",
    "    np.random.shuffle(m)\n",
    "    return m\n",
    "\n",
    "def matrix_to_dict(x):\n",
    "    return {CHARS[i]: CHARS[x[i].argmax()] for i in range(len(x))}\n",
    "\n",
    "def dict_to_matrix(d):\n",
    "    size = len(d)\n",
    "    m = np.zeros((size, size))\n",
    "    for k, v in d.iteritems():\n",
    "        m[LETTER_TO_INDEX[k]][LETTER_TO_INDEX[v]] = 1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def jumble(order, L):\n",
    "    \"\"\"\n",
    "    order is an array of indices, which correspond to points\n",
    "    from points1. L is the number of indices to swap\n",
    "    \"\"\"\n",
    "    if L > len(order):\n",
    "        return np.random.permutation(order)\n",
    "    \n",
    "    new_order = order.copy()\n",
    "    idx = np.arange(order.shape[0])\n",
    "    swappers = np.random.choice(idx, size=L, replace=False)\n",
    "    backwards = list(reversed(swappers))\n",
    "    new_order[swappers], new_order[backwards] = new_order[backwards], new_order[swappers]\n",
    "    return new_order\n",
    "\n",
    "def make_new_proposal(s, order, L):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    new_order = jumble(order, L)\n",
    "    return s, new_order\n",
    "\n",
    "def sa(start_params, loss_fn, trans_fn, t0=30, thermostat=5, reanneal=300, n=1000):\n",
    "    \"\"\"\n",
    "    As generic a simulated annealing implementation as I could \n",
    "    come up with. This actually tries to maximize loss_fn over the params\n",
    "    \"\"\"\n",
    "    prev_val = loss_fn(*start_params)\n",
    "    best_val = prev_val\n",
    "    prev_params = start_params\n",
    "    best_params = start_params\n",
    "    vals = []\n",
    "    params = []\n",
    "    Ls = []\n",
    "    t = t0\n",
    "    for i in range(n):\n",
    "        t *= 0.97\n",
    "        L = max(np.floor(np.sqrt(t)).astype(int), 1)\n",
    "        proposed = trans_fn(*prev_params, L=L)\n",
    "#         print \"POOP\", proposed\n",
    "        new_val = loss_fn(*proposed)\n",
    "#         print \"PREV VAL\", prev_val\n",
    "#         print \"NEW VAL:\", new_val\n",
    "        delta_val = new_val - prev_val\n",
    "        vals.append(new_val)\n",
    "        if delta_val > 0 or np.exp(delta_val / t) > np.random.rand():\n",
    "            params.append(proposed)\n",
    "            prev_val = new_val\n",
    "            prev_params = proposed\n",
    "            if new_val > best_val:\n",
    "                best_val = new_val\n",
    "                best_params = proposed\n",
    "        if i % reanneal == 0:\n",
    "            t *= thermostat\n",
    "        if t < 0.01: \n",
    "            t = t0\n",
    "    return best_params, best_val, params, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msg = str(open('message.txt').read())\n",
    "code_msg = c.encipher(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def order_to_dict(order):\n",
    "    return dict(zip(map(ord, wordify(order)), map(ord, CHARS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order = np.arange(len(CHARS))\n",
    "def likelihood(s, order):\n",
    "    guess = s.translate(order_to_dict(order))\n",
    "#     print \"GUESS:\", guess, str_likelihood(guess) \n",
    "    return str_likelihood(guess)\n",
    "    \n",
    "best_params, best_val, params, vals = sa([code_msg, order], likelihood, make_new_proposal, n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mapping():\n",
    "    m = np.identity(27)\n",
    "    np.random.shuffle(m)\n",
    "    return m\n",
    "\n",
    "def matrix_to_dict(x):\n",
    "    return {CHARS[i]: CHARS[x[i].argmax()] for i in range(len(x))}\n",
    "\n",
    "def dict_to_matrix(d):\n",
    "    size = len(d)\n",
    "    m = np.zeros((size, size))\n",
    "    for k, v in d.iteritems():\n",
    "        m[LETTER_TO_INDEX[k]][LETTER_TO_INDEX[v]] = 1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'here is a wig long secret message that i am typing bor the purposes ob encrypting fith my top secret encryption algorithm in order that no one fill we awle to read it unless they have some real top notch code wreaking technology ob fhich i am not afare in fhich case my secrets fill we stolen and i fill we very sad and my evil plans fill have ween thfarted oh fhat a shame fhat a horriwle shame that fould we so let us hope that it does not happen wecause i fould highly preber ib it did not here is some more text data wecause i am so conbident in my encryption skills hooray'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_msg.translate(order_to_dict(best_params[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(wordify(np.arange(27)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{32: 32,\n",
       " 97: 97,\n",
       " 98: 98,\n",
       " 99: 99,\n",
       " 100: 100,\n",
       " 101: 101,\n",
       " 102: 102,\n",
       " 103: 103,\n",
       " 104: 104,\n",
       " 105: 105,\n",
       " 106: 106,\n",
       " 107: 107,\n",
       " 108: 108,\n",
       " 109: 109,\n",
       " 110: 110,\n",
       " 111: 111,\n",
       " 112: 112,\n",
       " 113: 113,\n",
       " 114: 114,\n",
       " 115: 115,\n",
       " 116: 116,\n",
       " 117: 117,\n",
       " 118: 118,\n",
       " 119: 119,\n",
       " 120: 120,\n",
       " 121: 121,\n",
       " 122: 122}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_to_dict(np.arange(27))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
